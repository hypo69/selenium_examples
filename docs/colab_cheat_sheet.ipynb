{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hypo69/selenium_examples/blob/master/docs/colab_cheat_sheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSwrTt2ahxAQ"
      },
      "source": [
        "# Jupyter Notebook Colab: Шпаргалка по использованию интерактивной среды для анализа данных, машинного обучения и не только\n",
        "\n",
        "\n",
        "## Что такое Jupyter Notebook?\n",
        "\n",
        "Jupyter Notebook — это **веб-приложение с открытым исходным кодом**, которое позволяет создавать интерактивные документы, объединяющие код (например, Python, R, Julia), визуализации, текст и мультимедиа. Изначально проект назывался *IPython Notebook* и был создан в 2014 году как часть экосистемы Python. Сегодня Jupyter поддерживает **более 40 языков программирования**, а его название образовано от комбинации **Ju**lia, **Pyt**hon и **R**.\n",
        "\n",
        "### Ключевые особенности:\n",
        "- **Интерактивное выполнение кода** по ячейкам.\n",
        "- Поддержка **Markdown** и $\\LaTeX$ для документации:\n",
        "  \n",
        "   Тождество Эйлера: $e^{i\\pi} + 1 = 0$  \n",
        "   Формула Стирлинга: $n! \\sim \\sqrt{2\\pi n} \\left(\\frac{n}{e}\\right)^n$\n",
        "\n",
        "$$\n",
        "\\boxed{\n",
        "\\begin{aligned}\n",
        "& \\text{Основная теорема арифметики:} \\\\\n",
        "& \\text{Любое целое число } n > 1 \\text{ может быть представлено единственным образом} \\\\\n",
        "& \\text{в виде произведения простых чисел, с точностью до порядка сомножителей:} \\\\\n",
        "& n = p_1^{a_1} \\cdot p_2^{a_2} \\cdot ... \\cdot p_k^{a_k},\n",
        "\\end{aligned}\n",
        "}\n",
        "$$\n",
        "- Визуализация данных прямо в документе (графики, таблицы, анимации).\n",
        "- Экспорт в форматы HTML, PDF, LaTeX, презентации.\n",
        "- **Виджеты** для создания интерактивных интерфейсов.\n",
        "- Интеграция с облачными сервисами и инструментами Big Data.\n",
        "\n",
        "---\n",
        "\n",
        "## Установка и настройка\n",
        "\n",
        "1. **Установка через pip** (требуется Python 3.3+):\n",
        "   ```bash\n",
        "   pip install jupyter\n",
        "   ```\n",
        "\n",
        "2. **Запуск сервера**:\n",
        "   ```bash\n",
        "   jupyter notebook\n",
        "   ```\n",
        "   После этого в браузере откроется интерфейс Jupyter на `http://localhost:8888`.\n",
        "\n",
        "3. **Jupyter Lab** (расширенная версия):\n",
        "   ```bash\n",
        "   pip install jupyterlab\n",
        "   jupyter lab\n",
        "   ```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpGAa8GPiPYt"
      },
      "source": [
        "## Интерфейс и базовое использование\n",
        "\n",
        "### Основные элементы:\n",
        "1. **Панель управления** (Dashboard): список файлов и директорий.\n",
        "2. **Блокнот (Notebook)**: состоит из ячеек двух типов:\n",
        "   - **Code** — для написания кода.\n",
        "   - **Markdown** — для текста, формул, изображений.\n",
        "\n",
        "### Горячие клавиши:\n",
        "- **Shift + Enter** — выполнить ячейку.\n",
        "- **Esc + A/B** — добавить ячейку выше/ниже.\n",
        "- **Esc + M/Y** — сменить тип ячейки на Markdown/Code.\n",
        "\n",
        "### Горячие клавиши (в Colab):\n",
        "\n",
        "*   **Ctrl+Enter** (или **Shift+Enter**): Выполнить ячейку и перейти к следующей.\n",
        "*   **Ctrl+M A**: Вставить ячейку выше текущей.\n",
        "*   **Ctrl+M B**: Вставить ячейку ниже текущей.\n",
        "*   **Ctrl+M M**: Преобразовать ячейку в Markdown.\n",
        "*   **Ctrl+M Y**: Преобразовать ячейку в Code.\n",
        "*   **Ctrl+M D**: Удалить ячейку.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f_XG38HiYvl"
      },
      "source": [
        "## Примеры использования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6QkdxATiePj"
      },
      "source": [
        "### 1. Анализ данных о пассажирах Титаника с Pandas и Seaborn\n",
        "В этом примере я загружаю данные из github. Источник: https://github.com/datasciencedojo/datasets/blob/master/titanic.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uodw9xIsvc4V"
      },
      "source": [
        "#### Поля таблицы данных о пассажирах Титаника\n",
        "---\n",
        "- **PassengerId**: Уникальный идентификатор для каждого пассажира. Это просто номер пассажира в базе данных.\n",
        "-  **Survived**: Указывает, выжил пассажир (1) или нет (0).\n",
        " - 0: Пассажир погиб.\n",
        " - 1: Пассажир выжил.\n",
        "\n",
        "- **Pclass**: Класс билета пассажира. Обычно это соответствует уровню комфорта и расположению каюты.\n",
        " - 1: Первый класс (самый дорогой и комфортный).\n",
        " - 2: Второй класс.\n",
        " - 3: Третий класс (самый дешевый).\n",
        "\n",
        "- **Name**: Имя пассажира (включая звание, например, Mr., Mrs., Miss.).\n",
        "- **Sex**: Пол пассажира (male - мужской, female - женский).\n",
        "- **Age**: Возраст пассажира в годах. Обратите внимание, что в реальных данных часто бывают пропущенные значения возраста (NaN).\n",
        "- **SibSp**: Количество братьев/сестер (siblings) и супругов (spouses) на борту судна.\n",
        "- **Parch**: Количество родителей (parents) и детей (children) на борту судна.\n",
        "- **Ticket**: Номер билета пассажира.\n",
        "- **Fare**: Стоимость билета пассажира (в британских фунтах того времени).\n",
        "- **Cabin**: Номер каюты пассажира (если известен). Многие значения пропущены.\n",
        "- **Embarked**: Порт, в котором пассажир сел на корабль.\n",
        " - C: Cherbourg (Шербур, Франция).\n",
        " - Q: Queenstown (Квинстаун, Ирландия).\n",
        " - S: Southampton (Саутгемптон, Англия)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4miAIfR3EhE"
      },
      "source": [
        "#### Загузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYZagpqaiLUF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка данных с GitHub\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "titanic_df = pd.read_csv(url)\n",
        "\n",
        "# Вывод первых строк таблицы\n",
        "print(\"Первые 5 строк данных:\")\n",
        "print(titanic_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig6kX0Lv3OQc"
      },
      "source": [
        "#### Основная статистика\n",
        "\n",
        "\n",
        "*   **`count`**: Количество не-пустых (не-NaN) значений в столбце.  Это показывает, для скольких пассажиров доступна информация по данному признаку. Например, если `count` для столбца `Age` меньше, чем для других столбцов, это означает, что есть пропущенные значения возраста.\n",
        "\n",
        "*   **`mean`**: Среднее значение столбца.  Это сумма всех значений в столбце, деленная на количество значений (count).  Полезно для понимания \"типичного\" значения признака.\n",
        "    *   Для `Survived`:  Показывает долю выживших пассажиров (0.383838 означает, что примерно 38% пассажиров выжили).\n",
        "    *   Для `Pclass`:  Показывает средний класс билета (2.308642 говорит о том, что большинство пассажиров были в 2-м или 3-м классе).\n",
        "    *   Для `Age`:  Показывает средний возраст пассажиров (29.699118 лет).\n",
        "    *   Для `SibSp`:  Показывает среднее количество братьев/сестер и супругов на борту (0.523008).\n",
        "\n",
        "*   **`std`**: Стандартное отклонение.  Это мера разброса данных вокруг среднего значения.  Большое стандартное отклонение указывает на то, что значения в столбце сильно разбросаны, а маленькое - на то, что они сконцентрированы вокруг среднего.\n",
        "    *   Например, большое стандартное отклонение для возраста (14.526497) говорит о том, что возраст пассажиров сильно варьировался.\n",
        "\n",
        "*   **`min`**: Минимальное значение в столбце.  Показывает наименьшее значение признака.\n",
        "    *   Для `Survived`:  0 (кто-то не выжил).\n",
        "    *   Для `Pclass`: 1 (кто-то был в первом классе).\n",
        "    *   Для `Age`: 0.42 (самый маленький возраст - меньше года).\n",
        "    *   Для `SibSp`: 0 (у кого-то не было братьев/сестер или супругов на борту).\n",
        "\n",
        "*   **`25%`**: 25-й процентиль (или первый квартиль).  Это значение, ниже которого находится 25% данных.  Полезно для понимания распределения данных.\n",
        "    *   Например, 25% пассажиров младше 20.125 лет.\n",
        "\n",
        "*   **`50%`**: 50-й процентиль (или второй квартиль, или медиана).  Это значение, ниже которого находится 50% данных.  Медиана - это \"середина\" данных.  Она менее чувствительна к выбросам, чем среднее значение.\n",
        "    *   Например, половина пассажиров младше 28 лет.\n",
        "\n",
        "*   **`75%`**: 75-й процентиль (или третий квартиль).  Это значение, ниже которого находится 75% данных.\n",
        "    *   Например, 75% пассажиров младше 38 лет.\n",
        "\n",
        "*   **`max`**: Максимальное значение в столбце.  Показывает наибольшее значение признака.\n",
        "    *   Для `Survived`:  1 (кто-то выжил).\n",
        "    *   Для `Pclass`: 3 (кто-то был в третьем классе).\n",
        "    *   Для `Age`: 80 (самый старший возраст).\n",
        "    *   Для `SibSp`: 8 (у кого-то было 8 братьев/сестер или супругов на борту).\n",
        "\n",
        "**Вместе, эти статистики дают общее представление о распределении данных в каждом столбце, что полезно для:**\n",
        "\n",
        "*   Обнаружения пропущенных значений (сравнение `count` с общим количеством строк в DataFrame).\n",
        "*   Выявления выбросов (сравнение `min` и `max` со средним и квартилями).\n",
        "*   Понимания типичных значений и разброса данных.\n",
        "*   Принятия решений о предварительной обработке данных (например, нужно ли заполнять пропущенные значения возраста и как это лучше сделать).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L6Kpf3LraAI"
      },
      "outputs": [],
      "source": [
        "# Основная статистика\n",
        "print(\"\\nОписательная статистика:\")\n",
        "print(titanic_df.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdIXqMtw3S_v"
      },
      "source": [
        "#### Визуализация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_GlI1ctVULd"
      },
      "source": [
        "###### Визуализация распределения выживших"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWRaaeSXzOkd"
      },
      "outputs": [],
      "source": [
        "# Визуализация распределения выживших\n",
        "sns.countplot(x='Survived', data=titanic_df)\n",
        "plt.title('Распределение выживших')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLGaRrRp3Xpx"
      },
      "source": [
        "##### Зависимость выживания от класса билета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgYE-rm8zRCB"
      },
      "outputs": [],
      "source": [
        "# Зависимость выживания от класса билета\n",
        "\n",
        "sns.countplot(x='Pclass', hue='Survived', data=titanic_df)\n",
        "\"\"\"\n",
        "Args:\n",
        "  - `x: str` указывает, что столбец 'Pclass' будет использоваться в качестве оси X.\n",
        "  - `hue`: параметр, который добавляет еще одно измерение к графику. Он группирует столбцы по значению\n",
        "    указанного столбца и отображает их разными цветами.\n",
        "  - `data`: DataFrame` указывает, что данные будут использоваться из объекта titanic_df.\n",
        "\"\"\"\n",
        "plt.title('Выживаемость по классам билетов')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CajzAd9t3a-k"
      },
      "source": [
        "##### Гистограмма возраста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQU-Us0AzTDg"
      },
      "outputs": [],
      "source": [
        "# Гистограмма возраста\n",
        "sns.histplot(titanic_df['Age'].dropna(), kde=True) # Dropna чтобы избавиться от отсутствующих значений\n",
        "\"\"\"kde=True: аргумент функции sns.histplot указывает, что на гистограмме должна быть нарисована линия оценки\n",
        "плотности ядра (Kernel Density Estimate - KDE). KDE - это сглаженная кривая,\n",
        "которая аппроксимирует распределение данных. Она помогает визуально оценить форму распределения,\n",
        "особенно если данные не идеально соответствуют какой-либо известной форме, например, нормальному распределению)\n",
        "\"\"\"\n",
        "\n",
        "plt.title('Распределение возраста пассажиров')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYZT_hm_2-hw"
      },
      "source": [
        "### 2. Анализ набора данных `Diamonds`.\n",
        "Я использую набор данных \"Diamonds\", который содержит информацию о бриллиантах\n",
        "(размер, цвет, чистота, цена и т.д.). Этот набор данных доступен в библиотеке Seaborn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbejMi1b4DKb"
      },
      "source": [
        "#### Поля таблицы `Diamonds`:\n",
        "- **carat**: Вес бриллианта в каратах.\n",
        "- **cut**: Качество огранки (Fair, Good, Very Good, Premium, Ideal).\n",
        "- **color**: Цвет бриллианта (от J - наименее желательный, до D - бесцветный и самый желательный).\n",
        "- **clarity**: Чистота бриллианта.  \n",
        "(мера отсутствия включений и пятен, от I1 - худшая, до IF - безупречная).\n",
        "- **depth**: Общая высота бриллианта (измеряется от верха до калетты) деленная на средний диаметр.\n",
        "- **table**: Ширина верхней плоской грани бриллианта относительно его ширины.\n",
        "- **price**: Цена бриллианта в долларах США.\n",
        "- **x**: Длина в мм.\n",
        "- **y**: Ширина в мм.\n",
        "- **y**: Ширина в мм.\n",
        "- **z**: Глубина в мм.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiyR_1Bf52gt"
      },
      "source": [
        "#### Информация о таблице"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTbFEVyazUCG"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Загрузка набора данных Diamonds\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "\n",
        "# Вывод первых 5 строк\n",
        "print(\"Первые 5 строк данных:\")\n",
        "print(diamonds.head())\n",
        "\n",
        "# Информация о типах данных и пропущенных значениях\n",
        "print(\"\\nИнформация о типах данных и пропущенных значениях:\")\n",
        "print(diamonds.info())\n",
        "\n",
        "# Описательная статистика\n",
        "print(\"\\nОписательная статистика:\")\n",
        "print(diamonds.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLnVE6eITTrX"
      },
      "source": [
        "#### 1. Фильтрация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1r9T6qa3x_b"
      },
      "outputs": [],
      "source": [
        "# 1. Фильтрация: Выбор бриллиантов с ценой больше 5000 долларов\n",
        "expensive_diamonds = diamonds[diamonds['price'] > 5000]\n",
        "print(\"\\nБриллианты с ценой больше 5000 долларов:\")\n",
        "print(expensive_diamonds.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKf-6xc4ThlN"
      },
      "source": [
        "#### 2. Группировка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBIt9JtQ8Rag"
      },
      "outputs": [],
      "source": [
        "# 2. Группировка: Средняя цена бриллиантов по качеству огранки\n",
        "average_price_by_cut = diamonds.groupby('cut')['price'].mean()\n",
        "print(\"\\nСредняя цена бриллиантов по качеству огранки:\")\n",
        "print(average_price_by_cut)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg2soJbDTvXr"
      },
      "source": [
        "##### 2.1. Столбчатая диаграмма"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3zeeBINDDif"
      },
      "outputs": [],
      "source": [
        "# 2.1. Столбчатая диаграмма (Bar plot)\n",
        "plt.figure(figsize=(8, 6))\n",
        "average_price_by_cut.sort_values().plot(kind='bar', color='skyblue')  # Сортировка для наглядности\n",
        "plt.title('Средняя цена бриллиантов по качеству огранки', fontsize=14)\n",
        "plt.xlabel('Качество огранки', fontsize=12)\n",
        "plt.ylabel('Средняя цена', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')  # Поворот меток оси X\n",
        "plt.tight_layout()\n",
        "\"\"\"\n",
        "Функция plt.tight_layout() автоматически корректирует интервалы между подграфиками (subplots) в фигуре,\n",
        "чтобы они лучше помещались в отведенное пространство. Она предназначена для минимизации перекрытий между\n",
        "элементами графика, такими как заголовки, метки осей, и сами графики.\n",
        "Более подробно:\n",
        "- Автоматическая регулировка интервалов: Функция анализирует размеры и положения элементов графика (подграфиков,\n",
        "    заголовков, меток осей, легенд, цветовых шкал и т.д.) и пытается подобрать оптимальные интервалы,\n",
        "    чтобы избежать наложения.\n",
        "- Обработка сложных макетов: Особенно полезна для графиков с множеством подграфиков, нестандартными макетами\n",
        "     или графиками с длинными подписями и заголовками.\n",
        "- Оптимизация использования пространства: plt.tight_layout() старается максимально использовать доступное пространство\n",
        "    для отрисовки графиков, что часто приводит к более читабельному и визуально приятному результату.\n",
        "\n",
        "Применение до или после отрисовки: Обычно plt.tight_layout() вызывается после создания и заполнения подграфиков,\n",
        "но до сохранения фигуры в файл или отображения на экране (plt.show()).\n",
        "Вы можете вызывать ее повторно после изменения размеров элементов графика.\n",
        "\"\"\"\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FyY564UT2Ce"
      },
      "source": [
        "##### 2.2. Горизонтальная столбчатая диаграмма"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH3xroj19OiR"
      },
      "outputs": [],
      "source": [
        "# 2.2. Горизонтальная столбчатая диаграмма (Horizontal bar plot)\n",
        "plt.figure(figsize=(8, 6))\n",
        "average_price_by_cut.sort_values().plot(kind='barh', color='lightcoral') # Горизонтальная версия\n",
        "plt.title('Средняя цена бриллиантов по качеству огранки', fontsize=14)\n",
        "plt.xlabel('Средняя цена', fontsize=12)\n",
        "plt.ylabel('Качество огранки', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GEa3TTkUBUI"
      },
      "source": [
        "##### 2.3. Точечная диаграмма (Point plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8P06up99Raq"
      },
      "outputs": [],
      "source": [
        "# 2.3. Точечная диаграмма (Point plot)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.pointplot(x=average_price_by_cut.index, y=average_price_by_cut.values, color='mediumseagreen')\n",
        "plt.title('Средняя цена бриллиантов по качеству огранки', fontsize=14)\n",
        "plt.xlabel('Качество огранки', fontsize=12)\n",
        "plt.ylabel('Средняя цена', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXW8fiTJUQ8f"
      },
      "source": [
        "#### 3. Создание нового столбца"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P59mcbe8TZT"
      },
      "outputs": [],
      "source": [
        "# 3. Создание нового столбца: Плотность бриллианта (масса/объем, приближенно)\n",
        "diamonds['density'] = diamonds['carat'] / (diamonds['x'] * diamonds['y'] * diamonds['z'])\n",
        "print(\"\\nПервые 5 строк с добавленной колонкой 'density':\")\n",
        "print(diamonds.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z4WaDR1UbDG"
      },
      "source": [
        "#### 4. Визуализация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVl6u5xaUobJ"
      },
      "source": [
        "##### 4.1. Распределение цены бриллиантов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0PBpDXh8VYF"
      },
      "outputs": [],
      "source": [
        "# 4.1. Распределение цены бриллиантов\n",
        "sns.histplot(diamonds['price'])\n",
        "plt.title('Распределение цены бриллиантов')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8h_kKv7UyxC"
      },
      "source": [
        "##### 4.2. Гистограммы для числовых признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzItm74s7J0m"
      },
      "outputs": [],
      "source": [
        "# 4.2. Гистограммы для числовых признаков\n",
        "numerical_features = ['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(numerical_features):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    sns.histplot(diamonds[feature], kde=True)\n",
        "    plt.title(f'Распределение {feature}', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3iViLmF7vgA"
      },
      "outputs": [],
      "source": [
        "# 6. Ящики с усами (Boxplots) для числовых признаков по качеству огранки (cut)\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(numerical_features):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    sns.boxplot(x='cut', y=feature, data=diamonds)\n",
        "    plt.title(f'{feature} по качеству огранки', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQJ2I5b-73uJ"
      },
      "outputs": [],
      "source": [
        "# 7. Тепловая карта корреляции\n",
        "correlation_matrix = diamonds[numerical_features].corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Тепловая карта корреляции', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv9o609J79gn"
      },
      "outputs": [],
      "source": [
        "# 8. Диаграммы рассеяния (Scatter plots) между ценой и другими числовыми признаками\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.scatterplot(x='carat', y='price', data=diamonds, alpha=0.5)\n",
        "plt.title('Цена vs. Вес (carat)', fontsize=14)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.scatterplot(x='x', y='price', data=diamonds, alpha=0.5)\n",
        "plt.title('Цена vs. Длина (x)', fontsize=14)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.scatterplot(x='y', y='price', data=diamonds, alpha=0.5)\n",
        "plt.title('Цена vs. Ширина (y)', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtJWyNOA8FDl"
      },
      "outputs": [],
      "source": [
        "# 9. Столбчатые диаграммы (Countplots) для категориальных признаков\n",
        "categorical_features = ['cut', 'color', 'clarity']\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, feature in enumerate(categorical_features):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    sns.countplot(x=feature, data=diamonds, palette='viridis')\n",
        "    plt.title(f'Распределение {feature}', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vClpR0Ui_gM5"
      },
      "source": [
        "## 3. Классификация изображений с помощью MNIST и Keras\n",
        "Этот пример показывает, как загрузить набор данных MNIST (рукописные цифры) из Keras, построить и обучить простую нейронную сеть для классификации изображений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YxKtWUmGbhI"
      },
      "source": [
        "Функция `keras.datasets.mnist.load_data()` из Keras загружает набор данных MNIST. MNIST содержит 60 000 изображений рукописных цифр (от 0 до 9) для обучения и 10 000 изображений для тестирования.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1g9nT_Q_jH5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\"\"\"\n",
        "Функция `load_data()` возвращает два кортежа:\n",
        "\n",
        "- `(x_train, y_train)` Обучающий набор данных:\n",
        " - `x_train` Массив NumPy, содержащий изображения для обучения (60 000 изображений, каждое размером 28x28 пикселей).\n",
        " - `y_train` Массив NumPy, содержащий метки (цифры от 0 до 9), соответствующие каждому изображению в x_train.\n",
        "\n",
        "- `(x_test, y_test)` Тестовый набор данных:\n",
        " - `x_test` Массив NumPy, содержащий изображения для тестирования (10 000 изображений, каждое размером 28x28 пикселей).\n",
        " - `y_test` Массив NumPy, содержащий метки для тестовых изображений.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Нормализация данных (масштабирование к диапазону [0, 1])\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\"\"\"\n",
        "Код нормализуют значения пикселей в обучающем и тестовом наборах данных, масштабируя их к диапазону от 0 до 1.\n",
        "\n",
        "- `x_train.astype(\"float32\")` преобразует тип данных массива x_train в float32.\n",
        "  Это важно, потому что нейронные сети обычно работают лучше с числами с плавающей точкой.\n",
        "\n",
        "- `/ 255` делит все значения пикселей в массиве x_train на 255. Значения пикселей в изображениях MNIST находятся\n",
        "  в диапазоне   от 0 до 255. Деление на 255 масштабирует значения пикселей к диапазону от 0 до 1.\n",
        "\n",
        "Это называется нормализацией данных, и она помогает улучшить сходимость (скорость и стабильность обучения) нейронной сети.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Преобразование формы данных для нейронной сети (выпрямление изображений в векторы) (Reshape)\n",
        "x_train = x_train.reshape((-1, 28 * 28))\n",
        "x_test = x_test.reshape((-1, 28 * 28))\n",
        "\"\"\"\n",
        "Код преобразует каждое изображение из матрицы 28x28 в вектор длиной 784.\n",
        "Это необходимо, потому что полносвязные слои (Dense layers) в нейронной сети ожидают на входе векторы, а не матрицы.\n",
        "\n",
        "- `x_train.reshape((-1, 28 * 28))`: Изменяет форму массива x_train.\n",
        "  Исходно x_train имеет форму (60000, 28, 28) - 60 000 изображений размером 28x28.\n",
        "  - `reshape((-1, 28 * 28))` преобразует его в массив с формой (60000, 784).\n",
        "\n",
        "Args:\n",
        "  - `-1` означает, что NumPy должен автоматически вычислить размер первого измерения\n",
        "      (в данном случае, количество изображений - 60 000).\n",
        "  - `28 * 28 = 784` указывает, что второе измерение должно иметь размер 784.\n",
        "      Это означает, что каждое изображение 28x28 будет \"выпрямлено\" в вектор длиной 784.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Определение модели\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\", input_shape=(28 * 28,)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation=\"softmax\"), # 10 классов (цифры 0-9)\n",
        "])\n",
        "\"\"\"\n",
        "- `keras.Sequential([...])` Создает последовательную модель Keras. Последовательная модель означает,\n",
        "  что слои нейронной сети будут добавлены последовательно, один за другим.\n",
        "\n",
        "Args:\n",
        "  - `layers.Dense(512, activation=\"relu\", input_shape=(28 * 28,))` Добавляет полносвязный слой (Dense layer) с 512\n",
        "      нейронами. 512 Количество нейронов (узлов) в слое.\n",
        "  - `activation=\"relu\"` Функция активации ReLU (Rectified Linear Unit). ReLU - это популярная функция активации,\n",
        "    которая возвращает 0 для отрицательных входов и сам вход для положительных входов.\n",
        "  - `input_shape=(28 * 28,)` Указывает форму входных данных для первого слоя. 28 * 28 = 784, что соответствует размеру\n",
        "     выпрямленного изображения. `input_shape` нужно указывать только для первого слоя.\n",
        "  - `layers.Dropout(0.5)` добавляет слой Dropout.\n",
        "    `0.5` указывает долю нейронов, которые будут случайно \"выключены\" (их выход будет установлен в 0) во время обучения.\n",
        "    `Dropout` - это метод регуляризации, который помогает предотвратить переобучение\n",
        "    (когда модель хорошо работает на обучающих данных, но плохо на новых данных).\n",
        "  - `layers.Dense(10, activation=\"softmax\")` добавляет полносвязный выходной слой с 10 нейронами.\n",
        "    `10` количество нейронов в слое. Так как MNIST имеет 10 классов (цифры от 0 до 9), выходной слой должен иметь\n",
        "    10 нейронов, по одному для каждого класса.\n",
        "  - `activation=\"softmax\"` функция активации Softmax. Softmax преобразует выходные значения в вероятности, которые\n",
        "    суммируются в 1.     Например, если выход Softmax для данного изображения равен\n",
        "    [0.1, 0.05, 0.02, 0.08, 0.01, 0.7, 0.01, 0.01, 0.01, 0.01],\n",
        "    это означает, что модель предсказывает, что это изображение с вероятностью 70% является цифрой 5.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\"\"\"\n",
        "- `model.compile(...)` конфигурирует модель для обучения.\n",
        "\n",
        "- Args:\n",
        "  - `loss=\"sparse_categorical_crossentropy\"`: функция потерь (loss function).\n",
        "    Функция потерь измеряет, насколько хорошо модель предсказывает правильные ответы.\n",
        "    `sparse_categorical_crossentropy` - это подходящая функция потерь для задач классификации,\n",
        "    где метки являются целыми числами (в данном случае, цифры от 0 до 9).\n",
        "  - `optimizer=\"adam\"`: оптимизатор. Оптимизатор определяет, как будут обновляться веса нейронной сети во время обучения,\n",
        "    чтобы минимизировать функцию потерь. adam - это популярный и эффективный алгоритм оптимизации.\n",
        "  - `metrics=[\"accuracy\"]` метрики. Метрики используются для оценки производительности модели\n",
        "    во время обучения и тестирования.\n",
        "    `accuracy` - это доля правильно классифицированных изображений.\n",
        "\"\"\"\n",
        "\n",
        "# Обучение модели\n",
        "history = model.fit(x_train, y_train, epochs=2, batch_size=32, validation_split=0.2)\n",
        "\"\"\"\n",
        "- `model.fit(...)` Обучает модель на обучающих данных.\n",
        "Args:\n",
        "  - `x_train`, `y_train` Обучающие изображения и соответствующие метки.\n",
        "  - `epochs=2` Количество эпох (полных проходов по обучающему набору данных). Чем больше эпох,\n",
        "    тем больше времени модель будет учиться, но тем выше риск переобучения.\n",
        "  - `batch_size=32` Размер пакета (batch size). Обучающие данные разделяются на пакеты, и модель обновляет свои веса\n",
        "    после обработки каждого пакета. Меньший размер пакета требует больше времени на обучение, но может улучшить сходимость.\n",
        "  - `validation_split=0.2` Доля обучающих данных, которая будет использоваться для валидации\n",
        "    (оценки производительности модели во время обучения). В данном случае, 20% обучающих данных будут использоваться\n",
        "      как валидационный набор. Это позволяет отслеживать, как хорошо модель обобщает знания на данные,\n",
        "      которые она не видела во время обучения.\n",
        "Returns:\n",
        "  - `history: model.fit()` возвращает объект history, который содержит информацию о процессе обучения,\n",
        "    такую как значения функции потерь и метрик на каждой эпохе.\n",
        "\"\"\"\n",
        "\n",
        "# Оценка модели\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\"\"\"\n",
        "- `model.evaluate(...)` Оценивает производительность модели на тестовых данных.\n",
        "Args:\n",
        "  - `x_test`, `y_test` Тестовые изображения и соответствующие метки.\n",
        "  - `verbose=` Управляет выводом информации во время оценки. verbose=0 означает, что информация не будет выводиться.\n",
        "Returns\n",
        "  - `loss`, `accuracy`: model.evaluate() возвращает функцию потерь и метрики (в данном случае, точность) на тестовых данных.\n",
        "\"\"\"\n",
        "print(f\"Точность на тестовых данных: {accuracy:.4f}\")\n",
        "\n",
        "# Вывод графика обучения\n",
        "plt.plot(history.history['accuracy'], label='Точность на обучающих данных')\n",
        "plt.plot(history.history['val_accuracy'], label='Точность на проверочных данных')\n",
        "plt.xlabel('Эпоха')\n",
        "plt.ylabel('Точность')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJQMgFliSs8Q"
      },
      "source": [
        "## 4. Регрессия с использованием Boston Housing Dataset и Scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g7weY7NWju2"
      },
      "source": [
        "В этом примере я использую Boston Housing Dataset для построения модели линейной регрессии.  Этот набор данных доступен непосредственно из Scikit-learn.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJafd-FOYrYN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка данных о жилье в Бостоне из оригинального источника\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "\"\"\"\n",
        "- `pd.read_csv(...)` функция из библиотеки Pandas, которая используется для чтения данных из CSV-файла\n",
        "  (или файла с разделителями).\n",
        "\n",
        "Args:\n",
        "  - `data_url` переменная, которая содержит URL-адрес, откуда загружаются данные (http://lib.stat.cmu.edu/datasets/boston).\n",
        "\n",
        "  - `sep=\"\\s+\"` аргумент, который задает разделитель между значениями в файле.\n",
        "    - `\\s+` - это регулярное выражение, которое означает \"один или несколько пробельных символов\" (пробел, табуляция, перевод строки и т.д.).\n",
        "    Это необходимо, потому что в файле данных значения разделены пробелами, а не запятыми или другими стандартными разделителями.\n",
        "\n",
        "  - `skiprows=22` аргумент, который указывает, сколько строк нужно пропустить в начале файла.\n",
        "    В данном случае, пропускаются первые 22 строки, так как они содержат комментарии и описание данных, а не сами данные.\n",
        "\n",
        "  - `header=None` аргумент, который указывает, что в файле нет строки заголовка (названий столбцов). Pandas автоматически присвоит столбцам номера (0, 1, 2 и т.д.).\n",
        "\n",
        "Returns:\n",
        "  - `raw_df:DataFrame`, полученный в результате чтения CSV-файла. raw_df будет содержать \"сырые\" данные, которые еще нужно будет обработать.\n",
        "\"\"\"\n",
        "\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "\"\"\"\n",
        "  Эта строка выполняет операцию по извлечению признаков (features) из сырых данных.\n",
        "Она разделяет сырые данные на две части (строки с четными и нечетными индексами),\n",
        "выбирает нужные столбцы из каждой части и объединяет их горизонтально, чтобы создать матрицу признаков.\n",
        "Этот способ вызван особенностью хранения данных в файле.\n",
        "\n",
        "Args:\n",
        "  - `raw_df.values` свойство DataFrame raw_df, которое возвращает данные в виде массива NumPy.\n",
        "  - `raw_df.values[::2, :]` операция среза (slicing) массива NumPy, которая выбирает строки с четными индексами (0, 2, 4, ...) и все столбцы (:).\n",
        "      Эта часть кода выбирает строки, содержащие часть информации о признаках (features).\n",
        "  - `raw_df.values[1::2, :2]` операция среза, которая выбирает строки с нечетными индексами (1, 3, 5, ...) и только первые два столбца (:2).\n",
        "      Эта часть кода выбирает другую часть информации о признаках (features).\n",
        "  - `np.hstack([...])` функция из NumPy, которая выполняет горизонтальное объединение массивов.\n",
        "    Она объединяет массивы по столбцам.\n",
        "Returns:\n",
        "- `data:NumPy`  массив NumPy, представляющий собой матрицу признаков (features) для модели машинного обучения.\n",
        "\"\"\"\n",
        "\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "# Присваивание данных и целевой переменной X и y\n",
        "X, y = data, target\n",
        "\n",
        "# Разделение данных на обучающий и тестовый наборы\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\"\"\"\n",
        "Эта строка разделяет данные на обучающий и тестовый наборы, используя 20% данных для тестирования\n",
        "и фиксированное случайное состояние для воспроизводимости.\n",
        "\n",
        "- `train_test_split(...)` функция из библиотеки scikit-learn, которая используется для разделения данных на обучающий и тестовый наборы.\n",
        "Args:\n",
        "  - X: Матрица признаков (features).\n",
        "  - y: Целевая переменная.\n",
        "  - test_size=0.2 аргумент, который задает размер тестового набора. В данном случае, 20% данных будут использоваться для тестирования,\n",
        "    а остальные 80% - для обучения.\n",
        "  - random_state=42 аргумент, который задает случайное состояние (random seed) для перемешивания данных\n",
        "    перед разделением. Установка `random_state` гарантирует, что при каждом запуске кода\n",
        "    разделение данных будет происходить одинаково,что позволяет получать воспроизводимые результаты.\n",
        "\n",
        "Returns:\n",
        "  Функция train_test_split() возвращает четыре массива:\n",
        "\n",
        "  - X_train: Матрица признаков для обучающего набора.\n",
        "  - X_test: Матрица признаков для тестового набора.\n",
        "  - y_train: Целевая переменная для обучающего набора.\n",
        "  - y_test: Целевая переменная для тестового набора.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Создание и обучение модели линейной регрессии\n",
        "model = LinearRegression()\n",
        "\"\"\"\n",
        "`LinearRegression()` класс из библиотеки scikit-learn, который представляет собой модель линейной регрессии.\n",
        "Создает экземпляр модели линейной регрессии.\n",
        "\"\"\"\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\"\"\"\n",
        "Метод `fit()` находит оптимальные коэффициенты (веса) для линейной регрессии,\n",
        "которые минимизируют функцию потерь (например, среднеквадратичную ошибку) на обучающих данных.\n",
        "\n",
        "Args:\n",
        "  - X_train: Матрица признаков для обучающего набора.\n",
        "  - y_train: Целевая переменная для обучающего набора.\n",
        "\"\"\"\n",
        "\n",
        "# Получение предсказаний на тестовых данных\n",
        "y_pred = model.predict(X_test)\n",
        "\"\"\"\n",
        "Метод `predict()` использует обученную модель для предсказания значений целевой переменной для каждого образца в\n",
        "тестовом наборе.\n",
        "Он использует обученную модель для предсказания цен на жилье на основе тестовых данных.\n",
        "\n",
        "Args:\n",
        "  - `X_test`матрица признаков для тестового набора.\n",
        "Returns:\n",
        "  - `y_pred` переменная, в которую сохраняются предсказанные значения.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Оценка модели с использованием среднеквадратичной ошибки\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\"\"\"\n",
        "`mean_squared_error(y_test, y_pred)` функция из библиотеки scikit-learn, которая вычисляет среднеквадратичную ошибку (Mean Squared Error - MSE).\n",
        "MSE - это метрика, которая измеряет среднюю квадратичную разницу между предсказанными значениями и фактическими значениями.\n",
        "MSE позволяет оценить, насколько хорошо модель предсказывает цены на жилье. Чем меньше MSE, тем лучше модель.\n",
        "Args:\n",
        "  - y_test: Фактические значения целевой переменной для тестового набора.\n",
        "  - y_pred: Предсказанные значения целевой переменной для тестового набора.\n",
        "Returns:\n",
        "  - значение MSE\n",
        "\"\"\"\n",
        "print(f\"Среднеквадратичная ошибка: {mse:.2f}\")\n",
        "\n",
        "# Визуализация результатов\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Фактические значения\")\n",
        "plt.ylabel(\"Предсказанные значения\")\n",
        "plt.title(\"Фактические vs. Предсказанные цены на жилье\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwuFHiN4miYJ"
      },
      "source": [
        "## 4. Кластеризация с использованием Iris Dataset и K-means\n",
        "Этот пример демонстрирует кластеризацию данных Iris Dataset с помощью алгоритма K-means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNc71juJX7ZG"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\"\"\"\n",
        "Импорт функции `load_iris  из модуля `sklearn.datasets`.\n",
        "`sklearn.datasets` содержит различные наборы данных, которые часто используются для обучения и тестирования алгоритмов машинного обучения.\n",
        "`load_iris` - это функция, которая загружает набор данных Iris (Ирисы).\n",
        "\"\"\"\n",
        "from sklearn.cluster import KMeans\n",
        "\"\"\"\n",
        "KMeans - это класс, который реализует алгоритм K-means.\n",
        "`sklearn.cluster` содержит различные алгоритмы кластеризации, включая K-means.\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка данных\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "\n",
        "# Создание и обучение модели K-means (3 кластера, так как в Iris Dataset 3 вида ирисов)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "\"\"\"\n",
        "`KMeans(...)` Это конструктор класса KMeans, который создает экземпляр алгоритма K-means.\n",
        "Args:\n",
        "  - `n_clusters=3` аргумент, который указывает количество кластеров, на которые нужно разделить данные.\n",
        "    В данном случае, мы указываем n_clusters=3, так как набор данных Iris содержит 3 вида ирисов (Setosa, Versicolor, Virginica).\n",
        "    Каждый вид ирисов будет представлен своим кластером.\n",
        "  - `random_state=42` аргумент, который задает случайное состояние (random seed) для инициализации центроидов кластеров.\n",
        "    Установка random_state гарантирует, что при каждом запуске кода кластеризация будет происходить одинаково,\n",
        "    что позволяет получать воспроизводимые результаты.\n",
        "\"\"\"\n",
        "\n",
        "kmeans.fit(X)\n",
        "\"\"\"\n",
        "`kmeans.fit(...)` метод класса KMeans, который используется для обучения (fit) модели на данных.\n",
        "Метод `fit(`) находит оптимальное положение центроидов кластеров,\n",
        "которые минимизируют сумму квадратов расстояний от каждой точки до ближайшего центроида.\n",
        "Args:\n",
        "  - X данные (значения признаков), на которых будет обучаться модель.\n",
        "\"\"\"\n",
        "\n",
        "# Получение меток кластеров для каждой точки данных\n",
        "labels = kmeans.labels_\n",
        "\"\"\"\n",
        "`kmeans.labels_` атрибут обученной модели kmeans, который содержит метки кластеров,\n",
        "присвоенные каждой точке данных. Метка кластера - это целое число, которое указывает, к какому кластеру относится данная точка.\n",
        "\"\"\"\n",
        "\n",
        "# Визуализация кластеров (я использую первые два признака для простоты визуализации)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
        "plt.xlabel(iris.feature_names[0])\n",
        "plt.ylabel(iris.feature_names[1])\n",
        "plt.title('Кластеризация Iris Dataset с использованием K-means')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1qZmDqau5IQ"
      },
      "source": [
        "## 5. Использование TensorFlow Datasets\n",
        "\n",
        "TensorFlow Datasets предоставляет множество готовых к использованию наборов данных, упрощая процесс загрузки и подготовки данных для TensorFlow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq3GskhGubaI"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\"\"\"\n",
        "Импортирую библиотеку `tensorflow_datasets`.\n",
        "TensorFlow Datasets (TFDS) предоставляет готовые к использованию наборы данных,\n",
        "которые можно легко загрузить и использовать в TensorFlow.\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "\"\"\"\n",
        "TensorFlow - это библиотека для машинного обучения, разработанная Google.\n",
        "\"\"\"\n",
        "\n",
        "# Загрузка набора данных cats_vs_dogs\n",
        "(ds_train, ds_validation), ds_info = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\"\"\"\n",
        "`tfds.load(...)` функция из TensorFlow Datasets, которая загружает набор данных cats_vs_dogs,\n",
        "разделяет его на обучающий и проверочный наборы (80% / 20%), и сохраняет наборы данных\n",
        "и информацию о наборе данных в соответствующих переменных.\n",
        "\n",
        "Args:\n",
        "  - `cats_vs_dogs` Это имя набора данных, который нужно загрузить. `cats_vs_dogs` содержит изображения кошек и собак.\n",
        "  - `split=['train[:80%]', 'train[80%:]']` определяет, как разделить обучающий набор данных.\n",
        "  - `train[:80%]` использует первые 80% обучающего набора данных в качестве обучающего набора.\n",
        "  - `train[80%:]` использует оставшиеся 20% обучающего набора данных в качестве проверочного набора (validation set).\n",
        "  - `as_supervised=True` этот аргумент указывает, что набор данных должен быть загружен в \"контролируемом\" формате,\n",
        "      то есть каждый образец будет представлять собой кортеж (image, label), где image - это изображение,\n",
        "      а label - это метка класса (0 для кошки, 1 для собаки).\n",
        "  - `with_info=True` указывает, что вместе с набором данных должна быть загружена информация\n",
        "       о наборе данных (например, количество образцов, названия классов и т.д.).\n",
        "Returns:\n",
        "Функция tfds.load() возвращает два значения:\n",
        "  - `(ds_train, ds_validation)` кортеж, содержащий обучающий набор данных (ds_train)\n",
        "      и проверочный набор данных (ds_validation).\n",
        "      `ds_train` и `ds_validation` являются объектами `tf.data.Dataset`,\n",
        "      которые позволяют эффективно загружать и обрабатывать большие наборы данных.\n",
        "  - `ds_info` объект, содержащий информацию о наборе данных.\n",
        "\"\"\"\n",
        "\n",
        "# Функция для изменения размера изображений\n",
        "def resize_image(image, label):\n",
        "  \"\"\" функция изменяет размер изображения до 150x150 пикселей,\n",
        "  сохраняя метку класса.\n",
        "  Args:\n",
        "    `image` - изображение (объект типа tf.Tensor)\n",
        "    `label` - метка класса (объект типа tf.Tensor)\n",
        "  Returns:\n",
        "    измененное изображение (объект типа tf.Tensor) и его соответствующая метка класса (объект типа tf.Tensor)\n",
        "  \"\"\"\n",
        "  image = tf.image.resize(image, (150, 150))\n",
        "  return image, label\n",
        "\n",
        "# Применение функции изменения размера к данным\n",
        "ds_train = ds_train.map(resize_image)\n",
        "ds_validation = ds_validation.map(resize_image)\n",
        "\"\"\"\n",
        "Этот блок кода изменяет размер всех изображений в обучающем и проверочном наборах данных до 150x150 пикселей.\n",
        "- `ds_train.map(resize_image)` Применяет функцию `resize_image` к каждому элементу (изображению и метке)\n",
        "   в обучающем наборе данных `ds_train`. Метод `map()` преобразует каждый элемент набора данных, применяя к нему указанную функцию.\n",
        "- `ds_validation.map(resize_image)` Применяет функцию `resize_image` к каждому элементу в проверочном наборе данных `ds_validation`.\n",
        "\"\"\"\n",
        "\n",
        "# Настройка параметров пакетной обработки и кэширования\n",
        "batch_size = 32\n",
        "ds_train = ds_train.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "ds_validation = ds_validation.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\"\"\"\n",
        "Этот блок кода устанавливает размер пакета равным 32 и настраивает пакетную обработку\n",
        "и предварительную выборку для повышения производительности обучения.\n",
        "  - `batch_size = 32` задает размер пакета (batch size). Размер пакета определяет, сколько образцов будет обработано за одну итерацию обучения.\n",
        "  - `ds_train.batch(batch_size)` группирует элементы обучающего набора данных в пакеты размером batch_size.\n",
        "  - `.prefetch(buffer_size=tf.data.AUTOTUNE)` использует предварительную выборку (prefetching) для повышения производительности. Предварительная выборка позволяет загружать следующие пакеты данных в фоновом режиме, пока модель обрабатывает текущий пакет. tf.data.AUTOTUNE позволяет TensorFlow автоматически определять оптимальный размер буфера для предварительной выборки.\n",
        "Аналогичные действия выполняются для проверочного набора данных.\n",
        "\"\"\"\n",
        "\n",
        "# Пример отображения нескольких изображений из набора данных\n",
        "def show_batch(image_batch, label_batch):\n",
        "  \"\"\" Функция принимает два аргумента: image_batch (пакет изображений) и label_batch (пакет меток классов)\n",
        "  Args:\n",
        "    `image_batch` - пакет изображений (объект типа tf.Tensor)\n",
        "    `label_batch` - пакет меток классов (объект типа tf.Tensor)\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,10))\n",
        "  \"\"\"Создает новую фигуру Matplotlib размером 10x10 дюймов.\"\"\"\n",
        "\n",
        "  for n in range(25):\n",
        "    \"\"\"Цикл, который повторяется 25 раз (для отображения 25 изображений).\"\"\"\n",
        "    ax = plt.subplot(5,5,n+1)\n",
        "    \"\"\"Создает подграфик (subplot) на фигуре.\n",
        "    Фигура разделена на сетку 5x5, и текущий подграфик будет размещен в ячейке с номером n+1.\"\"\"\n",
        "\n",
        "    plt.imshow(image_batch[n].numpy().astype(\"uint8\"))\n",
        "    \"\"\" Отображает изображение на текущем подграфике.\n",
        "    - `image_batch[n]` Выбирает n-е изображение из пакета изображений.\n",
        "    - `.numpy()` преобразует тензор TensorFlow в массив NumPy.\n",
        "    - .astype(\"uint8\"): Преобразует тип данных массива NumPy в uint8 (беззнаковое 8-битное целое число),\n",
        "    что необходимо для правильного отображения изображений.\"\"\"\n",
        "\n",
        "    plt.title(ds_info.features['label'].int2str(label_batch[n].numpy()))\n",
        "    plt.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "for image_batch, label_batch in ds_train.take(1):\n",
        "    show_batch(image_batch, label_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds5hEMIP3OKF"
      },
      "source": [
        "# Расширенные возможности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-S48nm33TXn"
      },
      "source": [
        "## 1. Магические команды (работают и в Colab)\n",
        "\n",
        "*   `%timeit`: Измерение времени выполнения кода.\n",
        "*   `!ls`: Выполнение команд shell.\n",
        "*   `%%writefile my_script.py`:  Сохранение содержимого ячейки в файл."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06k68Zv3vKMs"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "import numpy as np\n",
        "np.random.randn(1000, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz0ixQo53iDR"
      },
      "source": [
        "## 2. Интерактивные виджеты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OC2cQ6h3c0g"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import interact\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_sine(frequency=1.0):\n",
        "  \"\"\"Отображает график синусоиды с заданной частотой.\"\"\"\n",
        "  x = np.linspace(0, 2 * np.pi, 400)\n",
        "  y = np.sin(frequency * x)\n",
        "  plt.figure(figsize=(8, 4))\n",
        "  plt.plot(x, y)\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.ylabel(\"sin(x)\")\n",
        "  plt.title(f\"Синусоида с частотой {frequency}\")\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n",
        "interact(plot_sine, frequency=(0.1, 5.0, 0.1));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0tFBsKq3yQ8"
      },
      "source": [
        "# 3. Использование GPU в Colab\n",
        "Colab предоставляет бесплатный доступ к GPU.  Чтобы включить GPU, выберите Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spdCFJ3H3rPZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Простой пример использования GPU\n",
        "with tf.device('/GPU:0'):\n",
        "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "  b = tf.constant([7.0, 8.0, 9.0, 10.0, 11.0, 12.0], shape=[3, 2], name='b')\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3WiIy9b4rC-"
      },
      "source": [
        "# 4. TensorBoard в Colab\n",
        "TensorBoard - это инструмент для визуализации обучения моделей TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWbzQz-U4ELw"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "# Определение callback для TensorBoard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Загрузка данных MNIST (пример для обучения)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Определение модели\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели с использованием callback TensorBoard\n",
        "model.fit(x=x_train, y=y_train, epochs=5, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
        "\n",
        "%tensorboard --logdir logs/fit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev3hgBGd49A9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}